{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a0424844",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image, ExifTags\n",
    "from retinaface import RetinaFace\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "76325926",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAW Train : ..\\data\\Train\n",
      "RAW Val   : ..\\data\\val\n",
      "Processed Train : ..\\data\\processed\\Train\n",
      "Processed Val   : ..\\data\\processed\\val\n"
     ]
    }
   ],
   "source": [
    "# Path dataset raw\n",
    "RAW_TRAIN = Path(\"../data/Train\")\n",
    "RAW_VAL   = Path(\"../data/val\")\n",
    "\n",
    "# Path dataset processed\n",
    "PROC_TRAIN = Path(\"../data/processed/Train\")\n",
    "PROC_VAL   = Path(\"../data/processed/val\")\n",
    "\n",
    "# Buat folder output jika belum ada\n",
    "PROC_TRAIN.mkdir(parents=True, exist_ok=True)\n",
    "PROC_VAL.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"RAW Train :\", RAW_TRAIN)\n",
    "print(\"RAW Val   :\", RAW_VAL)\n",
    "print(\"Processed Train :\", PROC_TRAIN)\n",
    "print(\"Processed Val   :\", PROC_VAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e3866ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jumlah kelas: 70\n",
      "['Abraham Ganda Napitu', 'Abu Bakar Siddiq Siregar', 'Ahmad Faqih Hasani', 'Aldi Sanjaya', 'Alfajar', 'Alief Fathur Rahman', 'Arkan Hariz Chandrawinata Liem', 'Bayu Ega Ferdana', 'Bayu Prameswara Haris', 'Bezalel Samuel Manik', 'Bintang Fikri Fauzan', 'Boy Sandro Sigiro', 'Desty Ananta Purba', 'Dimas Azi Rajab Aizar', 'Dito Rifki Irawan', 'Dwi Arthur Revangga', 'Dyo Dwi Carol Bukit', 'Eden Wijaya', 'Eichal Elphindo Ginting', 'Elsa Elisa Yohana Sianturi', 'Fajrul Ramadhana Aqsa', 'Falih Dzakwan Zuhdi', 'Fathan Andi Kartagama', 'Fayyadh Abdillah', 'Femmy Aprillia Putri', 'Ferdana Al Hakim', 'Festus Mikhael', 'Fiqri Aldiansyah', 'Freddy Harahap', 'Gabriella Natalya Rumapea', 'Garland Wijaya', 'Havidz Ridho Pratama', 'Ichsan Kuntadi Baskara', 'Ikhsannudin Lathief', 'Intan Permata Sari', 'JP. Rafi Radiktya Arkan. R. AZ', 'Joshia Fernandes Sectio Purba', 'Joshua Palti Sinaga', 'Joy Daniella V', 'Joyapul Hanscalvin Panjaitan', 'Kayla Chika Lathisya', 'Kenneth Austin Wijaya', 'Kevin Naufal Dany', 'Lois Novel E Gurning', 'Machzaul harmansyah', 'Martua Kevin A.M.H.Lubis', 'Muhammad Fasya Atthoriq', 'Muhammad Nelwan Fakhri', 'Muhammad Riveldo Hermawan Putra', 'Muhammad Zada Rizki', 'Mychael Daniel N', 'Nasya Aulia Efendi', 'Raditya Erza Farandi', 'Rahmat Aldi Nasda', 'Randy Hendriyawan', 'Rayhan Fadel Irwanto', 'Rayhan Fatih Gunawan', 'Reynaldi Cristian Simamora', 'Rizky Abdillah', 'Royfran Roger Valentino', 'Rustian Afencius Marbun', 'Shintya Ayu Wardani', 'Sikah Nubuahtul Ilmi', 'William Chan', 'Yohanna Anzelika Sitepu', 'Zakhi algifari', 'Zaky Ahmad Makarim', 'Zefanya Danovanta Tarigan', 'Zidan Raihan', 'hayyatul fajri']\n",
      "Sample image: ..\\data\\Train\\Abraham Ganda Napitu\\IMG_2138 - Abraham Ganda Napitu.jpeg\n"
     ]
    }
   ],
   "source": [
    "valid_ext = [\".jpg\", \".jpeg\", \".png\", \".jfif\"]\n",
    "\n",
    "# Ambil kelas dari Train\n",
    "classes = sorted([d.name for d in RAW_TRAIN.iterdir() if d.is_dir()])\n",
    "print(\"Jumlah kelas:\", len(classes))\n",
    "print(classes)\n",
    "\n",
    "# Ambil sample image\n",
    "sample_class = classes[0]\n",
    "sample_dir   = RAW_TRAIN / sample_class\n",
    "sample_images = [p for p in sample_dir.iterdir() if p.suffix.lower() in valid_ext]\n",
    "\n",
    "sample_image_path = sample_images[0]\n",
    "print(\"Sample image:\", sample_image_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "76781712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_with_correct_orientation(image_path):\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    try:\n",
    "        for orientation in ExifTags.TAGS.keys():\n",
    "            if ExifTags.TAGS[orientation] == \"Orientation\":\n",
    "                break\n",
    "\n",
    "        exif = img._getexif()\n",
    "\n",
    "        if exif is not None:\n",
    "            value = exif.get(orientation, None)\n",
    "            if value == 3:\n",
    "                img = img.rotate(180, expand=True)\n",
    "            elif value == 6:\n",
    "                img = img.rotate(270, expand=True)\n",
    "            elif value == 8:\n",
    "                img = img.rotate(90, expand=True)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return img.convert(\"RGB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5d62f11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_by_landmarks(img, landmarks, output_size=224):\n",
    "    # Landmark RetinaFace\n",
    "    left_eye  = np.array(landmarks[\"left_eye\"])\n",
    "    right_eye = np.array(landmarks[\"right_eye\"])\n",
    "    nose      = np.array(landmarks[\"nose\"])\n",
    "    mouth_l   = np.array(landmarks[\"mouth_left\"])\n",
    "    mouth_r   = np.array(landmarks[\"mouth_right\"])\n",
    "\n",
    "    # Template landmark FaceNet (5-point)\n",
    "    template = np.float32([\n",
    "        [38.2946, 51.6963],  # left eye\n",
    "        [73.5318, 51.5014],  # right eye\n",
    "        [56.0252, 71.7366],  # nose\n",
    "        [41.5493, 92.3655],  # left mouth\n",
    "        [70.7299, 92.2041],  # right mouth\n",
    "    ])\n",
    "\n",
    "    # Scale agar sesuai output_size\n",
    "    template[:, 0] *= (output_size / 112)\n",
    "    template[:, 1] *= (output_size / 112)\n",
    "\n",
    "    src = np.float32([left_eye, right_eye, nose, mouth_l, mouth_r])\n",
    "\n",
    "    # Transformasi affine dari landmark → template\n",
    "    M = cv2.estimateAffinePartial2D(src, template, method=cv2.LMEDS)[0]\n",
    "\n",
    "    aligned = cv2.warpAffine(img, M, (output_size, output_size), borderValue=0)\n",
    "    return aligned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9e39a0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_and_crop_retina(image_path, save_size=224):\n",
    "    # Load image + EXIF correction\n",
    "    try:\n",
    "        pil_img = load_with_correct_orientation(image_path)\n",
    "        img_np = np.array(pil_img)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    # RetinaFace detection\n",
    "    try:\n",
    "        result = RetinaFace.detect_faces(img_np)\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "    # Tidak ada wajah\n",
    "    if not isinstance(result, dict) or len(result.keys()) == 0:\n",
    "        return None\n",
    "\n",
    "    # Ambil wajah pertama\n",
    "    key = list(result.keys())[0]\n",
    "    face = result[key]\n",
    "\n",
    "    if \"landmarks\" not in face:\n",
    "        return None\n",
    "\n",
    "    landmarks = face[\"landmarks\"]\n",
    "\n",
    "    # ALIGN wajah berdasarkan landmark (template-based)\n",
    "    aligned_face = crop_by_landmarks(img_np, landmarks, output_size=save_size)\n",
    "\n",
    "    # Convert ke BGR (untuk OpenCV)\n",
    "    aligned_face = cv2.cvtColor(aligned_face, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "    return aligned_face\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "698f043f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Wajah tidak terdeteksi.\n"
     ]
    }
   ],
   "source": [
    "img = detect_and_crop_retina(str(sample_image_path))\n",
    "\n",
    "if img is None:\n",
    "    print(\"❌ Wajah tidak terdeteksi.\")\n",
    "else:\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Aligned & Cropped RetinaFace ✓\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a018a32e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25-11-28 19:50:37 - Directory C:\\Users\\ihyar/.deepface created\n",
      "25-11-28 19:50:37 - Directory C:\\Users\\ihyar/.deepface/weights created\n",
      "25-11-28 19:50:37 - retinaface.h5 will be downloaded from the url https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n",
      "To: C:\\Users\\ihyar\\.deepface\\weights\\retinaface.h5\n",
      "100%|██████████| 119M/119M [16:20<00:00, 121kB/s]    \n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m img \u001b[38;5;241m=\u001b[39m \u001b[43mdetect_and_crop_retina\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msample_image_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m img \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWajah tidak terdeteksi.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[11], line 18\u001b[0m, in \u001b[0;36mdetect_and_crop_retina\u001b[1;34m(image_path, save_size)\u001b[0m\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Ambil wajah pertama\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     19\u001b[0m face \u001b[38;5;241m=\u001b[39m result[key]\n\u001b[0;32m     21\u001b[0m facial_area \u001b[38;5;241m=\u001b[39m face[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacial_area\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "img = detect_and_crop_retina(str(sample_image_path))\n",
    "\n",
    "if img is None:\n",
    "    print(\"Wajah tidak terdeteksi.\")\n",
    "else:\n",
    "    plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "    plt.title(\"Hasil crop RetinaFace (aligned & tegak)\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
